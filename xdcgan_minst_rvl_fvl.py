# -*- coding: utf-8 -*-
"""XDCGAN-MINST-RVL-FVL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UBOzY5n5KsevH-j3znDhaFUcSDXg66Bp
"""

from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Activation, Flatten, Reshape
from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Convolution2D
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import LeakyReLU
from keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
import random
import datetime
from tqdm import tqdm_notebook
import pickle
# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
#print(X_train.shape)

z_dim = 100
import cv2 
X_train = X_train.reshape(60000, 28, 28, 1)
X_test = X_test.reshape(10000, 28, 28, 1)
X_train = X_train.astype('float32')/255
X_test = X_test.astype('float32')/255

X_train=X_train[0:30000]








 
nch = 20
g_input = Input(shape=[100])

 
# Generator
adam = Adam(lr=0.0002, beta_1=0.5)

g = Sequential()
g.add(Dense(7*7*112, input_dim=z_dim))
g.add(Reshape((7, 7, 112)))
g.add(BatchNormalization())
g.add(Activation(LeakyReLU(alpha=0.2)))
g.add(Conv2DTranspose(56, 5, strides=2, padding='same'))
g.add(BatchNormalization())
g.add(Activation(LeakyReLU(alpha=0.2)))
g.add(Conv2DTranspose(1, 5, strides=2, padding='same', activation='sigmoid'))
g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
g.summary()

d = Sequential()
d.add(Conv2D(56, 5, strides=2, padding='same', input_shape=(28, 28, 1), activation=LeakyReLU(alpha=0.2)))
d.add(Conv2D(112, 5, strides=2, padding='same'))
g.add(BatchNormalization())
g.add(Activation(LeakyReLU(alpha=0.2)))
d.add(Conv2D(224, 5, strides=2, padding='same'))
g.add(Activation(LeakyReLU(alpha=0.2)))
d.add(Flatten())
d.add(Dense(112, activation=LeakyReLU(alpha=0.2)))
d.add(Dense(1, activation='sigmoid'))
d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
d.summary()

d.trainable = False
inputs = Input(shape=(z_dim, ))
hidden = g(inputs)
output = d(hidden)
gan = Model(inputs, output)
gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
gan.summary()

def plot_loss(losses):
    """
    @losses.keys():
        0: loss
        1: accuracy
    """
    d_loss = [v[0] for v in losses["D"]]
    g_loss = [v[0] for v in losses["G"]]
    
    plt.figure(figsize=(6.4,4.8))
    plt.plot(d_loss,color='red', label="Discriminator loss")
    plt.plot(g_loss,color='green', label="Generator loss")
    plt.title("GAN : MNIST dataset")

    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig('loss.png')
    #plt.show()
    
def plot_generated(n_ex=20, dim=(2, 10), figsize=(48, 8)):
    noise = np.random.normal(0, 1, size=(n_ex, z_dim))
    generated_images = g.predict(noise)
    generated_images = generated_images.reshape(generated_images.shape[0], 28, 28)
    plt.figure(figsize=figsize)
    for i in range(generated_images.shape[0]):
        plt.subplot(dim[0], dim[1], i+1)
        #plt.imshow(generated_images[i, :, :], interpolation='nearest', cmap='gray_r')
        sss= str(i)
        
        #plt.imsave(sss, generated_images[i, :, :], cmap='gray_r')

        plt.axis('off')
    plt.tight_layout()
    plt.plot()
    plt.show()
 
 # Set up a vector (dict) to store the losses
losses = {"D":[], "G":[]}
samples = []

pic_val=[]
pic_val2=[]
def train(d,epochs=1, plt_frq=1, BATCH_SIZE=128):
    
    autoencoder =''
    autoencoder2 =''
    input_img = Input(shape=(784,))
    encoded = Dense(128, activation='relu')(input_img)
    encoded = Dense(64, activation='relu')(encoded)
    encoded = Dense(32, activation='relu')(encoded)

    decoded = Dense(64, activation='relu')(encoded)
    decoded = Dense(128, activation='relu')(decoded)
    decoded = Dense(784, activation='sigmoid')(decoded)

    autoencoder = Model(input_img, decoded)
    autoencoder2 = Model(input_img, decoded)
    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
    autoencoder2.compile(optimizer='adadelta', loss='binary_crossentropy')

    #batchCount = int(X_train.shape[0] / BATCH_SIZE)
    batchCount=100

    print('Epochs:', epochs)
    print('Batch size:', BATCH_SIZE)
    print('Batches per epoch:', batchCount)

    d_v=[]   
    ttt=[] 
    for e in tqdm_notebook(range(1, epochs+1)):
        a222 = datetime.datetime.now()
        if e == 1 or e%plt_frq == 0:
            print('-'*15, 'Epoch %d' % e, '-'*15)
        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):
            # Create a batch by drawing random index numbers from the training set
            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]
            image_batch = image_batch.reshape(image_batch.shape[0], image_batch.shape[1], image_batch.shape[2], 1)
            #print(image_batch.shape)
            # Create noise vectors for the generator
            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))
            
            # Generate the images from the noise
            generated_images = g.predict(noise)
            temp_test = image_batch.reshape(BATCH_SIZE,784)

            temp = generated_images.reshape(BATCH_SIZE,784)
            history2=autoencoder.fit(temp ,temp,
                epochs=1,
                batch_size=256,
                shuffle=True,verbose=0,
                validation_data=(temp_test, temp_test))
            

            history20=autoencoder2.fit(temp_test ,temp_test,
                epochs=1,
                batch_size=256,
                shuffle=True,verbose=0,
                validation_data=(temp, temp))


            val_loss = history2.history['val_loss']
            val_loss2 = history20.history['val_loss']
        
            


            samples.append(generated_images)
            X = np.concatenate((image_batch, generated_images))
            # Create labels
            y = np.zeros(2*BATCH_SIZE)
            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing

            # Train discriminator on generated images
            d.trainable = True
            d_loss = d.train_on_batch(X, y)
            d_v.append(d)
            tempi=random.randint(0,e-1)
            #d=d_v[tempi]

            # Train generator
            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))
            y2 = np.ones(BATCH_SIZE)
            d.trainable = False
            g_loss = gan.train_on_batch(noise, y2)

        # Only store losses from final batch of epoch
        print('RVL : ' + str(val_loss2[len( val_loss)-1]) + '---' + 'FVL : ' + str(val_loss[len( val_loss)-1]) )
        b222 = datetime.datetime.now()
        c=b222-a222
        ttt.append(c.microseconds)
        
        
        pic_val.append(val_loss[len( val_loss)-1])
        pic_val2.append(val_loss2[len( val_loss2)-1])
        losses["D"].append(d_loss)
        losses["G"].append(g_loss)

        # Update the plots
        if e == 1 or e%plt_frq == 0:
            plot_generated()
    print('time= ' + str(np.mean(ttt)))
    
    plot_loss(losses)
    
    return generated_images
    
    

b=train(d,epochs=10, plt_frq=20, BATCH_SIZE=128)
dbfile = open('XDC_FVL_ite_234', 'ab') 
      
# source, destination 
pickle.dump(pic_val2, dbfile)                      
dbfile.close() 

dbfile = open('XDC_RVL_ite_234', 'ab') 
      
# source, destination 
pickle.dump(pic_val, dbfile)                      
dbfile.close() 

for i in range(0,len(losses["G"])):
    print(losses["G"][i][0])